= Querying with {sqlpp}
:description: Parallel data management for complex queries over many records, using a familiar SQL-like syntax.
:nav-title: Querying with {sqlpp}
:page-topic-type: concept
:page-aliases: ROOT:n1ql-query,

include::project-docs:partial$attributes.adoc[]

[abstract]
{description}


include::{version-common}@sdk:shared:partial$n1ql-queries.adoc[tag=intro]


// Prepared Statements for Query Optimization
include::{version-common}@sdk:shared:partial$n1ql-queries.adoc[tag=prepared]

For the Node.js SDK, the `adhoc` parameter should be set to `false` for a plan to be prepared, or a prepared plan to be reused.
Do not turn off the `adhoc` flag for _every_ query to Server 6.0 and earlier, since only a finite number of query plans (currently 5000) can be stored in the SDK.

[source,javascript]
----
async function queryNamed() {
  const query = `
    SELECT airportname, city
    FROM \`travel-sample\`.inventory.airport
    WHERE city='London';`

  try {
    let result = await cluster.query(query, { adhoc: false })
    results.rows.forEach((row) => {
      console.log('Query row: ', row)
    return result
  } catch (error) {
    console.error('Query failed: ', error)
  }
}
----

// NB: xref:6.5@server as document does not exist in 7.0 branch.
CAUTION: *When running an application using Prepared Statements through the Node.js SDK* -- if you plan to upgrade Couchbase Server from 6.0.x or earlier to 6.5.0 or later, and are running a version of the Node.js SDK with an underlying LCB prior to 2.10.6, you will need to xref:6.5@server:install:upgrade-strategy-for-features.adoc#prepared-statements[restart the app or otherwise work around] a change in the Server's behaviour.


== Indexes

The Couchbase query service makes use of xref:{version-server}@server:learn:services-and-indexes/indexes/indexes.adoc[_indexes_] in order to do its work.
Indexes replicate subsets of documents from data nodes over to index nodes,
allowing specific data (for example, specific document properties) to be retrieved quickly,
and to distribute load away from data nodes in xref:{version-server}@server:learn:services-and-indexes/services/services.adoc[MDS] topologies.

[IMPORTANT]
In order to make a bucket queryable, it must have at least one index defined.

You can define a _primary index_ on a bucket.
When a _primary_ index is defined you can issue non-covered (see below) queries on the bucket as well.
This includes using the `META` function in the queries.

[source,n1ql]
----
CREATE PRIMARY INDEX ON `users`
----

You can also define indexes over given document fields and then use those fields in the query:

[source,n1ql]
----
CREATE INDEX ix_name ON `travel-sample`.inventory.hotel(name);
CREATE INDEX ix_email ON `travel-sample`.inventory.hotel(email);
----

This would allow you to query the _travel-sample_ bucket's hotel collection regarding a document's `name` or `email` properties, thus:

[source,n1ql]
----
SELECT name, email
FROM `travel-sample`.inventory.hotel
WHERE name="Glasgow Grand Central" OR email="grandcentralhotel@example.com";
----

Indexes help improve the performance of a query.
When an index includes the actual values of all the fields specified in the query,
the index _covers_ the query, and eliminates the need to fetch the actual values from the Data Service.
An index, in this case, is called a _covering index_, and the query is called a _covered_ query.
For more information, see xref:{version-server}@server:n1ql:n1ql-language-reference/covering-indexes.adoc[Covering Indexes].

You can also create and define indexes in the SDK using:

[source,javascript]
----
const indexMgr = cluster.queryIndexes();
await indexMgr.createPrimaryIndex('bucket_name')
await indexMgr.createIndex('bucket_name', 'ix_name', ['name'])
await indexMgr.createIndex('bucket_name', 'ix_email', ['email'])
----


== Index Building

Creating indexes on buckets with many existing documents can take a long time.
You can build indexes in the background, creating _deferred_ indexes.
The deferred indexes can be built together, rather than having to re-scan the entire bucket for each index.

[source,n1ql]
----
CREATE PRIMARY INDEX ON `travel-sample`.inventory.hotel WITH {"defer_build": true};
CREATE INDEX ix_name ON `travel-sample`.inventory.hotel(name) WITH {"defer_build": true};
CREATE INDEX ix_email ON `travel-sample`.inventory.hotel(email) WITH {"defer_build": true};
BUILD INDEX ON `travel-sample`.inventory.hotel(`#primary`, `ix_name`, `ix_email`);
----

The indexes are not built until the `BUILD INDEX` statement is executed.
At this point, the server scans all of the documents in the `users` bucket,
and indexes it for all of the applicable indexes (in this case, those that have a `name` or `email` field).

Building deferred indexes can also be done via the SDK:

[source,javascript]
----
const indexMgr = cluster.queryIndexes();
await indexMgr.createPrimaryIndex('bucket_name', {deferred: true})
await indexMgr.createIndex('bucket_name', 'ix_name', ['name'], {deferred: true})
await indexMgr.createIndex('bucket_name', 'ix_email', ['email'], {deferred: true})
await indexMgr.buildDeferredIndexes('bucket_name')
await indexMgr.watchIndexes('bucket_name', ['ix_name', 'ix_email', '#primary'], 2000)
----


// Index Consistency
include::{version-common}@sdk:shared:partial$n1ql-queries.adoc[tag=index-consistency]

The following options are available:

include::{version-server}@server:learn:page$services-and-indexes/indexes/index-replication.adoc[tag=scan_consistency]
////
* `not_bounded`: Executes the query immediately, without requiring any consistency for the query.
If index-maintenance is running behind, out-of-date results may be returned.
* `at_plus`: Executes the query, requiring indexes first to be updated to the timestamp of the last update.
If index-maintenance is running behind, the query waits for it to catch up.
* `request_plus`: Executes the query, requiring the indexes first to be updated to the timestamp of the current query-request.
If index-maintenance is running behind, the query waits for it to catch up.

For {sqlpp}, the default consistency is `not_bounded`.
////
Consider the following snippet:

[source,javascript]
----
var randomNumber = Math.floor(Math.rand() * 10000000)

await collection.upsert(`user:${randomNumber}`, {
  name: 'Brass Doorknob',
  email: 'brass.doorknob@juno.com',
  random: randomNumber
})

var res = await cluster.query(
  'SELECT name, email, random, META(default).id FROM default WHERE "Brass" IN name')
----

The above query may not return the newly inserted document because it has not yet been indexed.
The query is issued immediately after document creation, and in this case the query engine may process the query before the index has been updated.

If the above code is modified to use _RequestPlus_, query processing will wait until all updates have been processed and recalculated into the index from the point in time the query was received:

[source,javascript]
----
var res = await cluster.query(
  'SELECT name, email, random, META(default).id FROM default WHERE "Brass" IN name', {
    scanConsistency: couchbase.QueryScanConsistency.RequestPlus,
  })
----

This gives the application developer more control over the balance between performance (latency) and consistency,
and allows optimization on a case-by-case basis.
